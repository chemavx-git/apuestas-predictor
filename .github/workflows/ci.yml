name: CI & Deploy Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  DEFAULT_PYTHON_VERSION: '3.10'
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}

jobs:
  ci:
    name: Lint → Test → Build & Publish Docker
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.DEFAULT_PYTHON_VERSION }}

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Black
        run: black --check .

      - name: Run Flake8
        run: flake8 .

      - name: Run Tests
        run: pytest --maxfail=1 --disable-warnings -q

      # — Build & Push App Principal —
      - name: Build main app image
        run: |
          docker build . -f Dockerfile \
            -t gmktec-g5-app:${{ github.sha }}

      - name: Log in to GHCR
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Tag & Push main app
        run: |
          IMAGE=${{ env.IMAGE_REGISTRY }}/apuestas-predictor
          TAG=${{ github.sha }}
          docker tag gmktec-g5-app:${TAG} ${IMAGE}:${TAG}
          docker tag gmktec-g5-app:${TAG} ${IMAGE}:latest
          docker push ${IMAGE}:${TAG}
          docker push ${IMAGE}:latest

      # — Build & Push Microservicio de Ingesta —
      - name: Build ingestion service image
        run: |
          docker build services/ingestion \
            -f services/ingestion/Dockerfile \
            -t gmktec-g5-ingestion:${{ github.sha }}

      - name: Tag & Push ingestion service
        run: |
          IMAGE=${{ env.IMAGE_REGISTRY }}/ingestion
          TAG=${{ github.sha }}
          docker tag gmktec-g5-ingestion:${TAG} ${IMAGE}:${TAG}
          docker tag gmktec-g5-ingestion:${TAG} ${IMAGE}:latest
          docker push ${IMAGE}:${TAG}
          docker push ${IMAGE}:latest

  deploy:
    name: Deploy to K3s
    runs-on: ubuntu-latest
    needs: ci

    steps:
      - name: Checkout manifests
        uses: actions/checkout@v3
        with:
          fetch-depth: 1

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure kubeconfig
        run: |
          echo "${{ secrets.K3S_KUBECONFIG }}" | base64 --decode > kubeconfig.yaml
          chmod 600 kubeconfig.yaml
          export KUBECONFIG=$PWD/kubeconfig.yaml

      # — Secret de Ingesta —
      - name: Create ingestion-env Secret
        run: |
          kubectl create secret generic ingestion-env \
            --from-literal=FOOTBALL_DATA_TOKEN="${{ secrets.FOOTBALL_DATA_TOKEN }}" \
            --from-literal=ODDS_API_KEY="${{ secrets.ODDS_API_KEY }}" \
            --from-literal=DB_USER="${{ secrets.DB_USER }}" \
            --from-literal=DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
            --from-literal=DB_HOST="${{ secrets.DB_HOST }}" \
            --from-literal=DB_PORT="${{ secrets.DB_PORT }}" \
            --from-literal=DB_NAME="${{ secrets.DB_NAME }}" \
            --dry-run=client -o yaml | kubectl apply -f -

      # — Despliegue de la APP principal —
      - name: Apply main app manifests
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl rollout status deployment/apuestas-predictor

      # — Despliegue del servicio de ingesta —
      - name: Apply ingestion manifests
        run: |
          kubectl apply -f infra/manifests/ingestion.yaml
          kubectl rollout status deployment/ingestion

      - name: List Pods
        run: |
          kubectl get pods -l app=apuestas-predictor,app=ingestion -o wide
